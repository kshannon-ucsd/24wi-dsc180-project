{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 180B CNN Prototype\n",
    "\n",
    "### Getting the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/toy_v3.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df['Abnormal'] = df['Abnormal'].apply(lambda x: 0 if x == -1 else 1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(df)):\n",
    "    X.append(pydicom.dcmread('/Users/rohan/DSC180BXRayImageAuto/res/xray_imgs/' + df['dicom_id'][i] + '.dcm'))\n",
    "    \n",
    "print(X[0])\n",
    "plt.imshow(X[0].pixel_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    # valid_img = True\n",
    "    center = (img.shape[0] // 2, img.shape[1] // 2)\n",
    "    t, l, b, r = 0, 0, img.shape[0]-1, img.shape[1]-1\n",
    "    \n",
    "    # iterate through the image until we find a pixel that is black\n",
    "    while t < img.shape[0] and img[t, center[1]] < 100:\n",
    "        t += 1\n",
    "    while l < img.shape[1] and img[center[0], l] < 100:\n",
    "        l += 1\n",
    "    while b > 0 and img[b, center[1]] < 100:\n",
    "        b -= 1\n",
    "    while r > 0 and img[center[0], r] < 100:\n",
    "        r -= 1\n",
    "        \n",
    "    if t >= b or l >= r:\n",
    "        # valid_img = False\n",
    "        return img\n",
    "        \n",
    "    return img[t:b, l:r]\n",
    "\n",
    "def normalize_image(img):\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))  # Scale to [0,1]\n",
    "    img = (img * 255).astype(np.uint8)  # Convert to uint8\n",
    "    return img\n",
    "\n",
    "def apply_clahe(img, clip_limit=2.0, tile_grid_size=(8,8)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    return clahe.apply(img)\n",
    "\n",
    "def resize_image(img, target_size=(224, 224)):\n",
    "    return cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def add_random_rotation(img, max_angle=5):\n",
    "    angle = np.random.uniform(-max_angle, max_angle)\n",
    "    M = cv2.getRotationMatrix2D((img.shape[1] // 2, img.shape[0] // 2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "def convert_to_rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = crop_img(img)    \n",
    "    img = apply_clahe(img)\n",
    "    img = resize_image(img)\n",
    "    img = normalize_image(img)\n",
    "    img = add_random_rotation(img)\n",
    "    img = convert_to_rgb(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test preprocess_dicom\n",
    "for i in range(20):\n",
    "    test_img = X[i].pixel_array\n",
    "    # create side-by-side plots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(test_img, cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    processed = preprocess_image(test_img)\n",
    "    ax[1].imshow(processed, cmap = 'gray') if processed is not None else None\n",
    "    ax[1].set_title('Preprocessed Image')\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all images\n",
    "preprocessed_X = [preprocess_image(img.pixel_array) for img in X]\n",
    "\n",
    "preprocessed_X = np.array(preprocessed_X)\n",
    "\n",
    "# Convert to tensor to be fed to ResNet50\n",
    "preprocessed_X = torch.tensor(preprocessed_X)   \n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_X, df['Abnormal'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthy vs Unhealthy Lung Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_x_rays = []\n",
    "abnormal_x_rays = []\n",
    "i = 0\n",
    "while len(healthy_x_rays) < 10 or len(abnormal_x_rays) < 10:\n",
    "    if y_train.iloc[i] == 0:\n",
    "        healthy_x_rays.append(X_train[i])\n",
    "    else:\n",
    "        abnormal_x_rays.append(X_train[i])\n",
    "    i += 1\n",
    "        \n",
    "for i in range(10):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(healthy_x_rays[i], cmap='gray')\n",
    "    ax[0].set_title('Healthy X-Ray')\n",
    "    ax[1].imshow(abnormal_x_rays[i], cmap='gray')\n",
    "    ax[1].set_title('Abnormal X-Ray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications import ResNet50V2\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "resnet50 = ResNet50V2(weights = \"imagenet\", input_shape = (3, 224, 224), include_top = False)\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.add(resnet50)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 128, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "# Optimizer & Compilation\n",
    "initial_lr = 0.0005  # Lowered learning rate for stability\n",
    "model.compile(optimizer=Adam(learning_rate=initial_lr), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, \n",
    "                    batch_size=32, \n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=[early_stopping, lr_scheduler, model_checkpoint])\n",
    "\n",
    "# Save final trained model\n",
    "model.save('cnn_chest_xray_model_final.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# output precision, recall, f1-score\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
