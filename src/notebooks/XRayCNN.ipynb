{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O-NTuNnnw0z"
      },
      "source": [
        "# DSC 180B CNN Prototype\n",
        "\n",
        "### Data Loading and Getting the Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZhCC3SUoFKI",
        "outputId": "b621fc4d-1c5c-448f-a595-357c144f2a1e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMtca1ORnw00"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "gdHI_OVHnw00",
        "outputId": "d8e7197e-e4bf-4302-d10f-bde601ffccd7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data/X-Ray Data/Data_Entry_2017.csv')\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agAfUe7Bnw01"
      },
      "outputs": [],
      "source": [
        "def get_label(row):\n",
        "    if 'No Finding' in row['Finding Labels']:\n",
        "        return 0\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "u3zK6c4Onw01",
        "outputId": "e8fd395a-6c6a-4c22-c2c8-3d52e0ed314d"
      },
      "outputs": [],
      "source": [
        "df['Finding Labels'] = df.apply(lambda row: get_label(row), axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "9dmmqUQVwonZ",
        "outputId": "91fb6c92-50e4-410c-c0af-aaa4be119811"
      },
      "outputs": [],
      "source": [
        "# Create a directory to store the downloaded images\n",
        "download_dir = \"/content/downloaded_images\"\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "# Iterate through the dataframe and download the images\n",
        "image_paths = df['Image Index']\n",
        "for image_name in image_paths:\n",
        "  source_path = '/content/drive/MyDrive/data/X-Ray Data/' + image_name\n",
        "  destination_path = os.path.join(download_dir, image_name)\n",
        "  try:\n",
        "    shutil.copy2(source_path, destination_path) # copy2 preserves metadata\n",
        "  except FileNotFoundError:\n",
        "    continue\n",
        "  except Exception as e:\n",
        "    continue\n",
        "\n",
        "print(f\"Images downloaded to: {download_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXTd1erynw01"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "def normalize_image(img):\n",
        "    # normalize according to imagenet\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    img = (img - mean) / std\n",
        "    return img\n",
        "\n",
        "def random_horizontal_flip(img):\n",
        "    if np.random.rand() < 0.5:\n",
        "        img = cv2.flip(img, 1)\n",
        "    return img\n",
        "\n",
        "def color_jitter(img):\n",
        "    # Randomly adjust brightness, contrast, saturation, and hue\n",
        "    transform = transforms.ColorJitter(brightness=0.25, contrast=0.25)\n",
        "    img = transform(Image.fromarray(img))\n",
        "    return np.array(img)\n",
        "\n",
        "def resize_image(img, target_size=(224, 224)):\n",
        "    return cv2.resize(img, target_size)\n",
        "\n",
        "def convert_to_rgb(img):\n",
        "    return cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "def add_random_rotation(img, max_angle=5):\n",
        "    angle = np.random.uniform(-max_angle, max_angle)\n",
        "    M = cv2.getRotationMatrix2D((img.shape[1] // 2, img.shape[0] // 2), angle, 1)\n",
        "    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f83MFlhwnw01",
        "outputId": "44ff8092-dc9f-4a9b-bc12-760ec7996498"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "# load png images into X and y\n",
        "for i in range(len(df)):\n",
        "    image_name = df['Image Index'][i]\n",
        "    png_path = os.path.join('/content/downloaded_images', image_name) # Use os.path.join to create the path\n",
        "\n",
        "    # Check if the file exists before trying to read it\n",
        "    if not os.path.exists(png_path):\n",
        "        print(f\"Image file not found: {png_path}\")\n",
        "        continue\n",
        "\n",
        "    print(\"Image found\")\n",
        "\n",
        "    img = cv2.imread(png_path)\n",
        "\n",
        "    # Check if the image was loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image: {png_path}\")\n",
        "        continue\n",
        "\n",
        "    img = resize_image(img)\n",
        "    img = random_horizontal_flip(img)\n",
        "    img = color_jitter(img)\n",
        "    img = add_random_rotation(img)\n",
        "    img = normalize_image(img)\n",
        "\n",
        "    X.append(img)\n",
        "    y.append(df['Finding Labels'][i])\n",
        "\n",
        "    print(len(X))\n",
        "    print(len(y))\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd2qn8QgQuMi"
      },
      "outputs": [],
      "source": [
        "# Convert to tensor to be fed to ResNet50\n",
        "X = torch.tensor(X)\n",
        "\n",
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hchWDWbUQ0Om",
        "outputId": "899b68b6-169f-4d3e-d039-909bbbdb9bb5"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtvKCB_0nw02"
      },
      "source": [
        "### Healthy vs Unhealthy Lung Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gWaewoErnw02",
        "outputId": "4b222205-90b4-408c-fded-ea8f2f8240ae"
      },
      "outputs": [],
      "source": [
        "healthy_x_rays = []\n",
        "abnormal_x_rays = []\n",
        "i = 0\n",
        "while len(healthy_x_rays) < 10 or len(abnormal_x_rays) < 10:\n",
        "    if y_train[i] == 0:\n",
        "        healthy_x_rays.append(X_train[i])\n",
        "    else:\n",
        "        abnormal_x_rays.append(X_train[i])\n",
        "    i += 1\n",
        "\n",
        "for i in range(10):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    ax[0].imshow(healthy_x_rays[i], cmap='gray')\n",
        "    ax[0].set_title('Healthy X-Ray')\n",
        "    ax[1].imshow(abnormal_x_rays[i], cmap='gray')\n",
        "    ax[1].set_title('Abnormal X-Ray')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFjcxOYanw02",
        "outputId": "f3109189-486c-4091-f771-c9cc01f47ffe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
        "\n",
        "# Compute class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Load ResNet50V2\n",
        "resnet50 = ResNet50V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Unfreeze deeper layers for fine-tuning\n",
        "for layer in resnet50.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    resnet50,\n",
        "    Flatten(),\n",
        "    Dense(256, activation=\"relu\", kernel_regularizer=l2(1e-4)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Implement Cosine Annealing\n",
        "initial_lr = 1e-4\n",
        "cosine_decay_restarts = CosineDecayRestarts(initial_learning_rate=initial_lr,\n",
        "                                            first_decay_steps=5000,\n",
        "                                            t_mul=2.0,  # Increases period after each restart\n",
        "                                            m_mul=0.8,  # Reduce max learning rate after each restart\n",
        "                                            alpha=1e-6)\n",
        "\n",
        "# Compile model with Cosine Annealing scheduler\n",
        "model.compile(optimizer=Adam(learning_rate=cosine_decay_restarts),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=100,\n",
        "                    batch_size=16,\n",
        "                    class_weight=class_weights_dict,\n",
        "                    callbacks=[early_stopping, model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HS4RT6_nw02"
      },
      "outputs": [],
      "source": [
        "# create a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred > 0.5\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "\n",
        "# output precision, recall, f1-score\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqcnoIunkWTj",
        "outputId": "32678a3b-1150-4867-ba91-38975cf69ef3"
      },
      "outputs": [],
      "source": [
        "# prompt: Save the .keras and .h5 file to my google drive\n",
        "\n",
        "# Save the model to your Google Drive\n",
        "model.save('/content/drive/MyDrive/best_model.h5')\n",
        "model.save('/content/drive/MyDrive/best_model.keras')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
